{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        #print(os.path.join(dirname, filename))\n        pass\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-03-05T15:37:58.042487Z","iopub.execute_input":"2022-03-05T15:37:58.043234Z","iopub.status.idle":"2022-03-05T15:37:58.161007Z","shell.execute_reply.started":"2022-03-05T15:37:58.043191Z","shell.execute_reply":"2022-03-05T15:37:58.16012Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import json\nimport librosa\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nfrom tqdm import tqdm\nfrom sklearn.model_selection import train_test_split\nfrom tqdm.auto import tqdm\nfrom joblib import Parallel, delayed","metadata":{"execution":{"iopub.status.busy":"2022-03-05T15:37:58.389623Z","iopub.execute_input":"2022-03-05T15:37:58.390162Z","iopub.status.idle":"2022-03-05T15:37:58.394612Z","shell.execute_reply.started":"2022-03-05T15:37:58.390125Z","shell.execute_reply":"2022-03-05T15:37:58.393793Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!apt install -y ffmpeg","metadata":{"execution":{"iopub.status.busy":"2022-03-05T15:41:31.754785Z","iopub.execute_input":"2022-03-05T15:41:31.75568Z","iopub.status.idle":"2022-03-05T15:41:34.210937Z","shell.execute_reply.started":"2022-03-05T15:41:31.75563Z","shell.execute_reply":"2022-03-05T15:41:34.210068Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"AUDIO_PATH = '../input/birdclef-2022/train_audio'\nCLASSES = sorted(os.listdir(AUDIO_PATH))\nNUM_CLASSES = len(CLASSES)","metadata":{"execution":{"iopub.status.busy":"2022-03-05T16:24:51.719381Z","iopub.execute_input":"2022-03-05T16:24:51.719662Z","iopub.status.idle":"2022-03-05T16:24:51.724876Z","shell.execute_reply.started":"2022-03-05T16:24:51.719631Z","shell.execute_reply":"2022-03-05T16:24:51.724132Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class AudioParams:\n    \"\"\"\n    Parameters used for the audio data\n    \"\"\"\n    sr = 22050\n    duration = 5\n    n_mels = 224\n    fmin = 20\n    fmax = 16000","metadata":{"execution":{"iopub.status.busy":"2022-03-05T15:41:45.576284Z","iopub.execute_input":"2022-03-05T15:41:45.577009Z","iopub.status.idle":"2022-03-05T15:41:45.581401Z","shell.execute_reply.started":"2022-03-05T15:41:45.57697Z","shell.execute_reply":"2022-03-05T15:41:45.58059Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def crop_or_pad(y, length, sr, train=True, probs=None):\n    \"\"\"\n    Crops an array to a chosen length\n    Arguments:\n        y {1D np array} -- Array to crop\n        length {int} -- Length of the crop\n        sr {int} -- Sampling rate\n    Keyword Arguments:\n        train {bool} -- Whether we are at train time. If so, crop randomly, else return the beginning of y (default: {True})\n        probs {None or numpy array} -- Probabilities to use to chose where to crop (default: {None})\n    Returns:\n        1D np array -- Cropped array\n    \"\"\"\n    if len(y) <= length:\n        y = np.concatenate([y, np.zeros(length - len(y))])\n    else:\n        if not train:\n            start = 0\n        elif probs is None:\n            start = np.random.randint(len(y) - length)\n        else:\n            start = (\n                    np.random.choice(np.arange(len(probs)), p=probs) + np.random.random()\n            )\n            start = int(sr * (start))\n\n        y = y[start: start + length]\n\n    return y.astype(np.float32)","metadata":{"execution":{"iopub.status.busy":"2022-03-05T15:41:46.155263Z","iopub.execute_input":"2022-03-05T15:41:46.155901Z","iopub.status.idle":"2022-03-05T15:41:46.164442Z","shell.execute_reply.started":"2022-03-05T15:41:46.155859Z","shell.execute_reply":"2022-03-05T15:41:46.163431Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def preprocess_soundfiles(path, data=mydict):\n    for file in os.listdir(os.path.join(AUDIO_PATH, path)):\n        loc = os.path.join(AUDIO_PATH, path)\n        bird_call, _ = librosa.load(os.path.join(loc, file), mono=True)\n        segment = crop_or_pad(bird_call, AudioParams.duration * AudioParams.sr, sr=AudioParams.sr, train=True, probs=None)\n        mfcc = librosa.feature.mfcc(y=segment, sr=AudioParams.sr, hop_length=1024, n_mfcc=13)\n        mfcc = mfcc.T\n        data[\"mfcc\"].append(mfcc)\n        data[\"labels\"].append(os.path.basename(dirname))        ","metadata":{"execution":{"iopub.status.busy":"2022-03-05T16:57:45.73505Z","iopub.execute_input":"2022-03-05T16:57:45.735679Z","iopub.status.idle":"2022-03-05T16:57:45.743115Z","shell.execute_reply.started":"2022-03-05T16:57:45.73564Z","shell.execute_reply":"2022-03-05T16:57:45.742094Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mydict = {\n        \"mfcc\": [],\n        \"labels\": []\n        }","metadata":{"execution":{"iopub.status.busy":"2022-03-05T16:57:46.722913Z","iopub.execute_input":"2022-03-05T16:57:46.723434Z","iopub.status.idle":"2022-03-05T16:57:46.727673Z","shell.execute_reply.started":"2022-03-05T16:57:46.723394Z","shell.execute_reply":"2022-03-05T16:57:46.726736Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for path in os.listdir(AUDIO_PATH):\n    for file in os.listdir(os.path.join(AUDIO_PATH, path)):\n        loc = os.path.join(AUDIO_PATH, path)\n        print(os.path.join(loc, file))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"_ = Parallel(n_jobs=4)(delayed(preprocess_soundfiles)(path) for path in tqdm(os.listdir(AUDIO_PATH)))","metadata":{"execution":{"iopub.status.busy":"2022-03-05T16:57:48.989485Z","iopub.execute_input":"2022-03-05T16:57:48.989845Z","iopub.status.idle":"2022-03-05T17:06:40.475993Z","shell.execute_reply.started":"2022-03-05T16:57:48.989806Z","shell.execute_reply":"2022-03-05T17:06:40.474589Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mydict[\"mfcc\"]","metadata":{"execution":{"iopub.status.busy":"2022-03-05T17:07:08.960488Z","iopub.execute_input":"2022-03-05T17:07:08.961075Z","iopub.status.idle":"2022-03-05T17:07:08.966109Z","shell.execute_reply.started":"2022-03-05T17:07:08.96102Z","shell.execute_reply":"2022-03-05T17:07:08.965407Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X = np.array(data)\ntargets = np.array(labels)\ny = pd.get_dummies(targets).values","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train,X_val,y_train,y_val = train_test_split(X,y,random_state=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}